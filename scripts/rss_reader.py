import feedparser
import json
import os
from datetime import datetime

RSS_FEEDS = [
    "http://www.nature.com/nature/current_issue/rss",
    "https://www.science.org/action/showFeed?type=etoc&feed=rss&jc=science",
    "https://www.science.org/action/showFeed?type=etoc&feed=rss&jc=sciadv",
    "https://www.nature.com/ngeo.rss",
    "https://www.nature.com/ncomms.rss",
    "https://www.nature.com/natrevearthenviron.rss",
    "https://www.pnas.org/action/showFeed?type=searchTopic&taxonomyCode=topic&tagCode=earth-sci",
    "https://www.annualreviews.org/rss/content/journals/earth/latestarticles?fmt=rss",
    "https://rss.sciencedirect.com/publication/science/00128252",
    "https://rss.sciencedirect.com/publication/science/0012821X",
    "https://agupubs.onlinelibrary.wiley.com/feed/19448007/most-recent",
    "https://agupubs.onlinelibrary.wiley.com/feed/21699356/most-recent",
    "https://agupubs.onlinelibrary.wiley.com/feed/15252027/most-recent",
    "https://rss.sciencedirect.com/publication/science/00167037"
]

SEEN_FILE = "state/seen.json"
OUTPUT_FILE = "output/daily.md"

today = datetime.now().strftime("%Y-%m-%d")

# -------------------------
# åŠ è½½å·²æŠ“å–æ¡ç›®
# -------------------------
if os.path.exists(SEEN_FILE):
    with open(SEEN_FILE, "r", encoding="utf-8") as f:
        try:
            seen = json.load(f)
        except:
            seen = []
else:
    seen = []

# ç”Ÿæˆå·²æœ‰ uid é›†åˆï¼Œé˜²æ­¢é‡å¤
seen_uids = set(entry.get("uid") for entry in seen if "uid" in entry)

# -------------------------
# æŠ“å–æ–°æ¡ç›®
# -------------------------
new_entries = []

for feed_url in RSS_FEEDS:
    print(f"Parsing feed: {feed_url}")
    feed = feedparser.parse(feed_url)
    source_name = feed.feed.get("title", "Unknown Source")
    
    for entry in feed.entries:
        uid = entry.get("id") or entry.get("link")
        if not uid:
            continue
        if uid in seen_uids:
            continue  # å·²æŠ“å–è¿‡
        
        paper = {
            "uid": uid,
            "source": source_name,
            "title": entry.get("title", "No title"),
            "link": entry.get("link", ""),
            "summary": entry.get("summary", "").strip(),
            "date": today
        }
        new_entries.append(paper)
        seen_uids.add(uid)

# -------------------------
# æ›´æ–° seen.json
# -------------------------
if new_entries:
    print(f"æ–°å¢æ¡ç›®: {len(new_entries)}")
    seen.extend(new_entries)
    os.makedirs(os.path.dirname(SEEN_FILE), exist_ok=True)
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(seen, f, indent=2, ensure_ascii=False)
else:
    print("ä»Šå¤©æ²¡æœ‰æ–°å¢æ¡ç›®ã€‚")

# -------------------------
# å¯é€‰ï¼šæ›´æ–° Markdown æ–‡ä»¶ï¼ˆç®€æ˜“ç‰ˆï¼‰
# -------------------------
os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    f.write(f"# Daily Paper Digest â€” {today}\n")
    f.write(f"ä»Šæ—¥æ–°å¢è®ºæ–‡ï¼š{len(new_entries)}\n")
    f.write(f"å·²ç´¯è®¡æ”¶å½•ï¼š{len(seen)} ç¯‡\n")
    f.write("---\n\n")
    if new_entries:
        for p in new_entries:
            f.write(f"- **{p['title']}**  \n")
            f.write(f"  ğŸ”— {p['link']}\n")
            if p['summary']:
                f.write(f"  ğŸ“ {p['summary']}\n")
            f.write("\n")
    else:
        f.write("ä»Šå¤©æ²¡æœ‰æ–°å¢å†…å®¹ã€‚\n")

print("RSSæŠ“å–ä¸ seen.json æ›´æ–°å®Œæˆã€‚")
